# ğŸ¯ MongoDB Query Generator API

API REST unificada para generar queries MongoDB desde lenguaje natural y recibir sugerencias inteligentes usando LLM (Azure OpenAI).

## ğŸš€ CaracterÃ­sticas

- âœ… **Un solo endpoint inteligente** (`/assist/`)
- ğŸ§  **Sugerencias LLM** con Azure OpenAI
- ğŸ“Š **ValidaciÃ³n y ayuda automÃ¡tica**
- ğŸ¥ **Health check**
- ğŸ“š **DocumentaciÃ³n automÃ¡tica** (Swagger UI)

## ğŸ› ï¸ InstalaciÃ³n

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Configurar Azure OpenAI
Crea un archivo `.env` basado en `env_example.txt`:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo
```

### 3. Ejecutar la API
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“– Uso de la API

### DocumentaciÃ³n Interactiva
Accede a [http://localhost:8000/docs](http://localhost:8000/docs) para la documentaciÃ³n Swagger UI.

### Endpoint Ãšnico

#### `/assist/` (POST)
Genera una query MongoDB y sugiere mejoras o ayuda usando LLM.

**Ejemplo de request:**
```json
{
  "collection": "labs",
  "natural_text": "desanidar todos los niveles de devices hasta transactions, agrupar por fecha, deviceId, proyectar campo reg concatenando los valores segÃºn la plantilla, ordenar por fecha"
}
```

**Ejemplo de respuesta exitosa:**
```json
{
  "query": "db.labs.aggregate([...])",
  "suggestions": "Considera especificar el formato de la fecha para mayor claridad...",
  "status": "success"
}
```

**Ejemplo de respuesta con error:**
```json
{
  "error": "Campo 'deviceId' no encontrado en la colecciÃ³n 'labs'...",
  "suggestions": "Â¿QuizÃ¡s quisiste decir 'device_id'? Revisa los campos disponibles...",
  "status": "error"
}
```

### Health Check
```bash
GET /health/
```

## ğŸ³ Docker

### Construir imagen
```bash
docker build -t mongoquery-api .
```

### Ejecutar contenedor
```bash
docker run -p 8000:8000 --env-file .env mongoquery-api
```

## ğŸ’° Control de Costos
- Sugerencias LLM solo cuando es necesario
- Modelo econÃ³mico (GPT-35-turbo)
- LÃ­mite de tokens por respuesta

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno
| Variable | DescripciÃ³n | Requerido |
|----------|-------------|-----------|
| `AZURE_OPENAI_API_KEY` | API key de Azure OpenAI | âœ… |
| `AZURE_OPENAI_ENDPOINT` | Endpoint de Azure OpenAI | âœ… |
| `AZURE_OPENAI_DEPLOYMENT` | Nombre del deployment/modelo en Azure | âœ… |

## ğŸš€ Despliegue en Azure

Sigue los pasos de la secciÃ³n anterior para App Service o usa el workflow de GitHub Actions.

## ğŸ› Troubleshooting
- Si `/assist/` responde con error, revisa los logs y la configuraciÃ³n de variables de entorno.
- Si no ves `/docs`, revisa el comando de inicio y el nombre del archivo principal.

## ğŸ“Š Monitoreo
- Usa `/health/` para verificar el estado de la API y la conexiÃ³n con LLM. 